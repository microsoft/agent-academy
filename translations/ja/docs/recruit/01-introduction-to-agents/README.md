<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d6706e107678264168d77b2e107710b1",
  "translation_date": "2025-10-18T03:03:33+00:00",
  "source_file": "docs/recruit/01-introduction-to-agents/README.md",
  "language_code": "ja"
}
-->
# 🚨 ミッション01: エージェントの概要

## 🕵️‍♂️ コードネーム: `OPERATION AI AGENT DECODE`

> **⏱️ 作戦時間:** `約30分 – 情報収集のみ、現場作業は不要`

🎥 **ウォークスルーを見る**

[![エージェントの概要動画サムネイル](../../../../../translated_images/video-thumbnail.56c0520a784a1a84608827574db5010a6f965836fb120255de402d20f2259f15.ja.jpg)](https://www.youtube.com/watch?v=BhPz_zicUnM "YouTubeでウォークスルーを見る")

## 🎯 ミッション概要

新しい仲間へようこそ。エージェントを構築する前に、それを支えるAIの概念をしっかりと理解する必要があります。このミッションでは、会話型AI、大規模言語モデル（LLM）、検索強化生成（RAG）、そしてCopilot Studioで作成できるエージェントの種類についての基礎知識を身につけます。

## 🔎 目標

このミッションでは以下を学びます:

1. 会話型AIとは何か、そしてその重要性  
1. 大規模言語モデル（LLM）がチャット体験をどのように支えるか  
1. 検索強化生成（RAG）がもたらす利点  
1. 会話型エージェントと自律型エージェントの違い  
1. Copilot Studioのエージェントがこれらの概念をどのように活用するか  

さあ、始めましょう！

---

## 会話型AIとは？

会話型AIとは、テキストや音声などの人間の言語を理解し、処理し、自然に応答できるシステムを指します。例えば、ヘルプデスクのチャットボットやお気に入りのアプリに搭載された仮想パーソナルアシスタントなどが挙げられます。内部では、ほとんどの現代の会話型AIは大規模言語モデル（LLM）に依存しており、次のセクションで詳しく説明します。

### 重要性

- **ユーザー体験:** 会話型インターフェースは、メニューをクリックするよりも直感的であることが多いです。  
- **スケーラビリティ:** 1つのエージェントが数十、数百の同時会話を処理できます。  
- **効率性:** カスタムのルールベースのスクリプトを構築する代わりに、LLM搭載エージェントはユーザー入力に応じて柔軟に対応します。  
- **拡張性:** 適切な設計があれば、エージェントは知識ベースにアクセスしたり、APIに接続したり、ビジネスワークフロー内で「デジタル同僚」として機能することができます。

---

## 大規模言語モデル（LLM）101

ほとんどの会話型AIシステムの中心には**大規模言語モデル**があります。これらは膨大なテキストコーパスで訓練されたニューラルネットワークで、言語の統計的なパターンを学習し、まとまりのある文章を生成したり、質問に答えたり、アイデアを出したりすることができます。以下のポイントを理解しておきましょう:

1. **訓練データ:** LLMはテラバイト単位のテキスト（ウェブページ、書籍、記事など）を取り込みます。この「世界の知識」により、多くのトピックに対応できます。  
1. **トークン化:** テキストはトークン（単語、サブワード、文字など）と呼ばれる小さな単位に分割されます。モデルは1つずつトークンを予測します。  
1. **コンテキストウィンドウ:** 各LLMには一度に「見る」ことができるトークンの上限があります。その上限を超えると、以前のトークンは切り捨てられます。  
1. **プロンプト:** LLMと対話する際にはプロンプトを送信します。プロンプトが良ければ良いほど、応答は焦点が合い、関連性が高くなります。  
1. **ゼロショット vs. ファインチューニング:** ゼロショットはLLMをそのまま使用すること（生の重みのみ）。ファインチューニングは、モデルを特定の分野のデータで調整し、ニーズに合わせてより正確に回答できるようにすることです。

!!! Tip "プロのヒント"
    一般的な例えとして、LLMは「超賢いオートコンプリート」のようなものです。人間の脳のように意味を真に理解するわけではありませんが、次に最適な単語（またはフレーズ）を予測する能力に非常に優れています。

---

## 検索強化生成（RAG）

LLMが静的な訓練データにのみ依存すると、誤った情報を生成したり、古くなる可能性があります。RAGは、モデルが回答を作成する前に最新の情報を「検索」できるようにすることでこれを解決します。RAGの仕組みは以下の通りです:

1. **ユーザーの質問:** ユーザーが質問をします（例:「Contosoの四半期収益の最新情報は？」）。  
1. **検索ステップ:** システムが知識源（文書、内部データベース、SharePointライブラリなど）を検索して関連する情報を見つけます。  
1. **補強:** 検索された情報がLLMプロンプトの前後に追加されます。  
1. **生成:** LLMはユーザーの質問と検索されたコンテキストの両方を取り込み、最新のデータに基づいた応答を生成します。  

RAGを使用することで、エージェントは社内のWiki、プラグインAPI、FAQ知識ベースを呼び出し、静的に公開されたモデルパラメータに限定されない回答を返すことができます。

---

## 会話型エージェント vs. 自律型エージェント

Copilot Studioのコンテキストでは、**エージェント**という用語は複数の種類のAIアシスタントを指します。以下のように区別すると役立ちます:

**会話型エージェント:**

- 主に双方向の対話に焦点を当てる。  
- 会話の複数ターンにわたってコンテキストを保持する。  
- 通常、事前定義されたフローやトリガーによって調整される（例:「ユーザーがXと言ったら、Yで応答する」）。  
- カスタマーサポート、FAQ、ガイド付きインタラクション、スケジュール管理、簡単なQ&Aに最適。  
  - 例:  
    - HRポリシーに関する質問に答えるTeamsチャットボット。  
    - SharePointページ上でフォームの記入を案内するPower Virtual Agentsボット。  

**自律型エージェント:**

- 単なるチャットのやり取りを超え、ユーザーの代わりに**アクションを実行**できる。  
- LLMの推論ループ（「計画 → 実行 → 観察 → 再計画」を考える）を使用してタスクを完了する。  
- 外部ツールやAPIに接続する（例: Power Automateフローを呼び出す、カレンダー招待を送信する、Dataverseのデータを操作する）。  
- 常に人間のプロンプトを必要とせず、一度トリガーされると複数ステップのプロセスを自律的に処理できる。  
  - 例:  
    - 旅行プランを作成し、フライトを予約し、確認メールを送信するエージェント。  
    - Teams会議に参加し、リアルタイムで文字起こしを行い、OneNoteにエグゼクティブサマリーを書く「会議要約エージェント」。  

!!! Info "重要な違い"
    会話型エージェントはユーザー入力を待ち、対話に専念します。自律型エージェントは、広範なツールアクセスを使用して計画を立て、実行する一連のステップを積極的に行います。

---

## Copilot Studioのエージェント

**Copilot Studio**は、会話型と自律型の両方のシナリオを1つのフレームワークで統合します。Copilot Studioがエージェント構築をどのように支援するかを以下に示します:

1. **ビジュアルエージェントデザイナー:** チャットとアクションワークフローのプロンプト、メモリ、ツールを定義するためのローコードキャンバス。  
1. **LLM構成:** OpenAIモデルやMicrosoftのエンタープライズ向けGPTから選択し、パフォーマンスとコストニーズに合わせる。  
1. **検索コネクタ:** SharePoint、OneDrive、Azure Cognitive Search、Dataverseの事前構築済み統合により、RAGをすぐに利用可能。  
1. **カスタムツールと機能:** エージェントが自律的に呼び出せるカスタムHTTPアクションやPower Automateフローを定義。  
1. **マルチモーダル対応:** テキストだけでなく、画像、ファイル、構造化データを取り込んでコンテキストを充実させる。  
1. **公開と配布:** エージェントが完成したら、Microsoft 365 Copilotに公開して（Teams、SharePoint、Outlookなどで利用可能）、またはウェブページにスタンドアロンのチャットウィジェットとして埋め込むことができます。

---

## 🎉 ミッション完了

これでエージェントとAIの基礎概念の概要を学びました。以下を理解しました:

1. **LLM = エージェントの「頭脳」**  
   - 言語理解と生成を担当。  
   - トークン数が多いほどコンテキストが豊かになるが、1回の呼び出しのコストも高くなる。  

1. **RAG = リアルタイム知識統合**  
   - 静的なLLMと常に変化するデータソースのギャップを埋める。  
   - 関連する文書や記録をLLMプロンプトに取り込む。  

1. **会話型 vs. 自律型**  
   - **会話型:** 対話フローとコンテキスト保持に焦点を当てる（例:「セッションメモリ」）。  
   - **自律型:** エージェントが外部ツールやサービスを呼び出す「アクションブロック」を追加。  

---
次は、[Copilot Studioの基本](../02-copilot-studio-fundamentals/README.md)を学びます！

気を引き締めて、仲間。あなたのAIの旅はまだ始まったばかりです！

## 📚 戦術的リソース

🔗 [Copilot Studio ドキュメント ホーム](https://learn.microsoft.com/microsoft-copilot-studio/)

---

<img src="https://m365-visitor-stats.azurewebsites.net/agent-academy/recruit/01-introduction-to-agents" alt="分析" />

---

**免責事項**:  
この文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書を正式な情報源としてご参照ください。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤認について、当方は一切の責任を負いません。