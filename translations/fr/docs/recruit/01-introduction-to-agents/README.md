<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d6706e107678264168d77b2e107710b1",
  "translation_date": "2025-10-17T19:13:30+00:00",
  "source_file": "docs/recruit/01-introduction-to-agents/README.md",
  "language_code": "fr"
}
-->
# üö® Mission 01 : Introduction aux agents

## üïµÔ∏è‚Äç‚ôÇÔ∏è NOM DE CODE : `OP√âRATION D√âCODAGE AGENT IA`

> **‚è±Ô∏è Dur√©e de l'op√©ration :** `~30 minutes ‚Äì uniquement des informations, pas de travail sur le terrain requis`

üé• **Regardez la vid√©o explicative**

[![Miniature de la vid√©o Introduction aux agents](../../../../../translated_images/video-thumbnail.56c0520a784a1a84608827574db5010a6f965836fb120255de402d20f2259f15.fr.jpg)](https://www.youtube.com/watch?v=BhPz_zicUnM "Regardez la vid√©o explicative sur YouTube")

## üéØ R√©sum√© de la mission

Bienvenue, recrue. Avant de plonger dans la cr√©ation d'agents, vous devez bien comprendre les concepts d'IA qui les alimentent. Cette mission vous fournira des connaissances de base sur l'IA conversationnelle, les mod√®les de langage √©tendus (LLMs), la g√©n√©ration augment√©e par r√©cup√©ration (RAG) et les types d'agents que vous pouvez cr√©er dans Copilot Studio.

## üîé Objectifs

Dans cette mission, vous apprendrez :

1. Ce qu'est l'IA conversationnelle et pourquoi elle est importante  
1. Comment les mod√®les de langage √©tendus (LLMs) alimentent les exp√©riences de chat  
1. Ce que la g√©n√©ration augment√©e par r√©cup√©ration (RAG) apporte  
1. La diff√©rence entre les agents conversationnels et les agents autonomes  
1. Comment les agents dans Copilot Studio exploitent ces concepts  

Plongeons dans le sujet !

---

## Qu'est-ce que l'IA conversationnelle ?

L'IA conversationnelle d√©signe tout syst√®me capable de comprendre, traiter et r√©pondre au langage humain ‚Äì qu'il s'agisse de texte ou de parole ‚Äì d'une mani√®re naturelle. Pensez aux chatbots dans les centres d'assistance ou aux assistants personnels virtuels dans vos applications pr√©f√©r√©es. En coulisses, la plupart des IA conversationnelles modernes reposent sur des mod√®les de langage √©tendus (LLMs), que nous aborderons ensuite.

### Pourquoi c'est important

- **Exp√©rience utilisateur :** Les interfaces conversationnelles sont souvent plus intuitives que de naviguer dans des menus.  
- **√âvolutivit√© :** Un agent peut g√©rer des dizaines ou des centaines de conversations simultan√©es.  
- **Efficacit√© :** Au lieu de cr√©er des scripts bas√©s sur des r√®gles, les agents aliment√©s par des LLM s'adaptent instantan√©ment aux entr√©es des utilisateurs.  
- **Extensibilit√© :** Avec un bon design, les agents peuvent acc√©der √† des bases de connaissances, se connecter √† des API ou agir comme des "collaborateurs num√©riques" dans les flux de travail d'entreprise.

---

## Mod√®les de langage √©tendus (LLMs) 101

Au c≈ìur de la plupart des syst√®mes d'IA conversationnelle se trouvent les **mod√®les de langage √©tendus** ‚Äì des r√©seaux neuronaux entra√Æn√©s sur des corpus de texte massifs. Ils apprennent les mod√®les statistiques du langage pour g√©n√©rer des phrases coh√©rentes, r√©pondre √† des questions ou m√™me proposer des id√©es. Points cl√©s √† comprendre :

1. **Donn√©es d'entra√Ænement :** Les LLMs ing√®rent des t√©raoctets de texte (pages web, livres, articles). Cette "connaissance du monde" leur permet de r√©pondre sur de nombreux sujets.  
1. **Tokenisation :** Le texte est divis√© en unit√©s plus petites appel√©es tokens (mots, sous-mots ou caract√®res). Le mod√®le pr√©dit un token √† la fois.  
1. **Fen√™tre de contexte :** Chaque LLM a une limite sur le nombre de tokens qu'il peut "voir" en m√™me temps. Au-del√† de cette limite, les tokens pr√©c√©dents sont tronqu√©s.  
1. **Incitation (Prompting) :** Vous interagissez avec un LLM en lui envoyant une incitation. Plus votre incitation est pr√©cise, plus la r√©ponse sera pertinente.  
1. **Zero-shot vs. Fine-tuning :** Zero-shot signifie utiliser un LLM tel quel (juste ses poids bruts). Fine-tuning signifie ajuster le mod√®le avec des donn√©es sp√©cifiques au domaine pour qu'il r√©ponde plus pr√©cis√©ment √† vos besoins.

!!! Tip "Astuce Pro"
    Une analogie courante est que le LLM est comme un "autocompl√©teur super-intelligent". Il ne comprend pas vraiment le sens comme un cerveau humain, mais il est extr√™mement dou√© pour pr√©dire le prochain mot (ou phrase) dans une s√©quence.

---

## G√©n√©ration augment√©e par r√©cup√©ration (RAG)

Lorsque les LLMs se basent uniquement sur des donn√©es d'entra√Ænement statiques, ils peuvent halluciner ou devenir obsol√®tes. La RAG r√©sout ce probl√®me en permettant au mod√®le de "consulter" des informations fra√Æches avant de composer une r√©ponse. En r√©sum√©, la RAG fonctionne ainsi :

1. **Requ√™te utilisateur :** Un utilisateur pose une question (par exemple, "Quelles sont les derni√®res nouvelles sur les r√©sultats trimestriels de Contoso ?").  
1. **√âtape de r√©cup√©ration :** Le syst√®me interroge une source de connaissances (documents, bases de donn√©es internes, biblioth√®ques SharePoint, etc.) pour trouver des passages pertinents.  
1. **Augmentation :** Les passages r√©cup√©r√©s sont ajout√©s ou plac√©s avant l'incitation du LLM.  
1. **G√©n√©ration :** Le LLM ing√®re √† la fois la question de l'utilisateur et le contexte r√©cup√©r√©, puis g√©n√®re une r√©ponse bas√©e sur des donn√©es actualis√©es.  

Avec la RAG, votre agent peut consulter des wikis internes d'entreprise, des API de plugins ou rechercher dans une base de connaissances FAQ ‚Äì et fournir des r√©ponses qui ne sont pas limit√©es aux param√®tres statiques du mod√®le.

---

## Agents conversationnels vs. agents autonomes

Dans le contexte de Copilot Studio, le terme **agent** peut d√©signer plusieurs types d'assistants IA. Il est utile de distinguer :

**Agents conversationnels :**

- Se concentrent principalement sur le dialogue √† deux sens.  
- Conservent le contexte sur plusieurs tours de conversation.  
- G√©n√©ralement orchestr√©s via des flux ou des d√©clencheurs pr√©d√©finis (par exemple, "Si l'utilisateur dit X, r√©pondre avec Y").  
- Id√©al pour le support client, les FAQ, les interactions guid√©es, la planification ou les questions simples.  
  - Exemples :  
    - Un chatbot Teams qui r√©pond aux questions sur les politiques RH.  
    - Un bot Power Virtual Agents sur une page SharePoint pour guider les utilisateurs √† travers un formulaire.  

**Agents autonomes :**

- Vont au-del√† du simple dialogue ; ils peuvent **agir** au nom de l'utilisateur.  
- Utilisent des boucles de raisonnement LLM (penser "planifier ‚Üí agir ‚Üí observer ‚Üí replanifier") pour accomplir des t√¢ches.  
- Se connectent √† des outils ou API externes (par exemple, appeler un flux Power Automate, envoyer des invitations de calendrier, manipuler des donn√©es dans Dataverse).  
- Fonctionnent sans incitations humaines constantes ‚Äì une fois d√©clench√©s, ils peuvent g√©rer des processus multi-√©tapes de mani√®re autonome.  
  - Exemples :  
    - Un agent qui g√©n√®re un itin√©raire de voyage, r√©serve des vols et envoie des confirmations par email.  
    - Un agent "R√©sum√© de r√©union" qui rejoint un appel Teams, le transcrit en temps r√©el et r√©dige un r√©sum√© ex√©cutif dans OneNote.  

!!! Info "Diff√©rence cl√©"
    Les agents conversationnels attendent les entr√©es des utilisateurs et se limitent au dialogue. Les agents autonomes planifient et ex√©cutent de mani√®re proactive une s√©quence d'√©tapes en utilisant un acc√®s √©tendu aux outils.

---

## Agents dans Copilot Studio

**Copilot Studio** unifie les sc√©narios conversationnels et autonomes sous un m√™me cadre. Voici comment Copilot Studio vous aide √† cr√©er des agents :

1. **Concepteur visuel d'agents :** Une interface low-code pour d√©finir les incitations, la m√©moire et les outils pour les flux de chat et d'action.  
1. **Configurations LLM :** Choisissez parmi divers mod√®les OpenAI ou GPT de niveau entreprise de Microsoft pour r√©pondre √† vos besoins en termes de performance et de co√ªt.  
1. **Connecteurs de r√©cup√©ration :** Int√©grations pr√©construites pour SharePoint, OneDrive, Azure Cognitive Search et Dataverse, permettant la RAG d√®s le d√©part.  
1. **Outils et fonctions personnalis√©s :** D√©finissez des actions HTTP personnalis√©es ou des flux Power Automate que votre agent peut invoquer de mani√®re autonome.  
1. **Support multimodal :** Au-del√† du texte, les agents Copilot Studio peuvent ing√©rer des images, des fichiers ou des donn√©es structur√©es pour enrichir le contexte.  
1. **Publication et distribution :** Une fois votre agent pr√™t, vous pouvez le publier sur Microsoft 365 Copilot (pour que les utilisateurs l'invoquent dans Teams, SharePoint, Outlook, etc.) ou l'int√©grer comme widget de chat autonome sur une page web.

---

## üéâ Mission accomplie

Vous avez maintenant termin√© votre introduction aux agents et aux concepts fondamentaux de l'IA. Vous comprenez :

1. **LLMs = Le "cerveau" de votre agent**  
   - Responsable de la compr√©hension et de la g√©n√©ration du langage.  
   - Plus de tokens = contexte plus riche, mais aussi co√ªt par appel plus √©lev√©.  

1. **RAG = Int√©gration de connaissances en temps r√©el**  
   - Comble le foss√© entre un LLM statique et des sources de donn√©es en constante √©volution.  
   - R√©cup√®re et injecte des documents ou des enregistrements pertinents dans l'incitation du LLM.  

1. **Agents conversationnels vs. autonomes**  
   - **Conversationnels :** Se concentrent sur le flux de dialogue et la conservation du contexte (par exemple, "M√©moire de session").  
   - **Autonomes :** Ajoutent des "blocs d'action" permettant √† l'agent d'appeler des outils ou services externes.

---
Ensuite, vous explorerez les [fondamentaux de Copilot Studio](../02-copilot-studio-fundamentals/README.md) !

Restez vigilant, recrue - votre voyage dans l'IA ne fait que commencer !

## üìö Ressources tactiques

üîó [Page d'accueil de la documentation Copilot Studio](https://learn.microsoft.com/microsoft-copilot-studio/)

---

<!-- markdownlint-disable-next-line MD033 -->
<img src="https://m365-visitor-stats.azurewebsites.net/agent-academy/recruit/01-introduction-to-agents" alt="Analytique" />

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.