# Personalizing Agent Responses

--8<-- "disclaimer.md"

## üïµÔ∏è‚Äç‚ôÇÔ∏è CODENAME: `OPERATION ARCHETYPE`

> **‚è±Ô∏è Operation Time Window:** `~45 minutes`

## üéØ Mission Brief

Welcome back, Agent. In [Mission 04](../04-agent-instructions/README.md) - you learnt how to define your agent with instructions and invoke tools to equip your agent in handling requests.

Your assignment, should you choose to accept it, is **Operation Archetype** - focusing on the model of the agent and format agent responses for maximum user understanding and shape your agent‚Äôs responses to be clear, effective, and on point..

TBC

Choose the right model for your agent and format responses to be impactful and easy to follow.

## üîé Objectives

In this mission, you'll learn:

1. TBC
1. TBC
1. TBC
1. TBC
1. TBC

## ü§î What is the Agent Model?

The _agent model_ is the underlying generative AI engine powering your Copilot agent‚Äôs responses. Copilot Studio lets you select which model your agent uses, enabling you to leverage different strengths (speed, output quality, cost, etc.) depending on your scenario. The model you choose determines how your agent thinks and responds, for example, one model may respond faster, another may produce more detailed answers, while another might excel at complex reasoning.

### üé≠ Why it matters

Selecting the appropriate model ensures your agent performs optimally for your use case. Each available model has distinct capabilities and specializations, so aligning the model with your requirements (such as quick replies vs. deep analysis) can improve user satisfaction and manage costs.

### ü™Å Available models

#### OpenAI models

AI capabilities evolve rapidly, and Copilot Studio keeps up by offering a range of Azure OpenAI models. As of 2025, the primary models to choose from include Microsoft‚Äôs GPT-4.1 family, the ‚Äúo‚Äù series for reasoning, and the latest GPT-5 previews. The following table summarizes the main choices and what each is best suited for:

| Model Version | Status | Key Strengths | Ideal Use Cases |
|-------|----------|-------------|-----------|
| **GPT‚Äë4o (Default)** | General Availability | - Fast, cost-effective responses. - Good for most standard tasks with moderate complexity | Everyday Q&A, summaries, routine helpdesk scenarios where quick answers matter and budget is limited |
| **GPT-4.1** | Preview | - Higher-quality outputs, superior for complex tasks - Larger AI model with more advanced reasoning than GPT-4.1 Mini (may be slightly slower) | Complex queries, detailed content generation or analysis. Suitable for projects needing high accuracy and can afford higher latency or cost |
| **o3 (Generative‚ÄØOpenAI)** | General Availability | - Specialized for reasoning and decision logic - Excels at nuanced problem-solving and complex analysis tasks | Use when your agent must perform sophisticated reasoning, such as intricate planning, multi-step problem solving, or data analysis with critical thinking |
| **GPT‚Äë5 Auto** | Experimental | - Latest-generation model with improved context awareness and up-to-date training (Sept 2024) - Handles the highest complexity in planning and analytical tasks with slower, more methodical responses. | Cutting-edge scenarios needing the most context-aware answers or enhanced document/image processing. Use to evaluate advanced capabilities early, but not yet for mission-critical production due to preview status. |
| **GPT‚Äë5 Reasoning** | Experimental | - Latest model optimized for complex reasoning (trained up to Oct 2024) - High scores in document understanding and response accuracy | Advanced reasoning tasks where top-tier analytical capability is required (such as extensive planning, interpreting complex data). Again, use cautiously in testing since it‚Äôs a preview model. |

!!! warning

    - Experimental/preview models (like GPT-5 Chat) are accessible for testing new capabilities before they‚Äôre production-ready. They may have limited testing and higher variability in performance.

    - They are not recommended for production use because of possible instability (variable quality, latency, or even time-outs). Always review any _Preview_ model‚Äôs limitations and consider using them only in non-critical environments. Use them in _Sandbox_ or _Developer_ environments. If you do publish an agent with an experimental model, usage will still be billed at that model‚Äôs established rate.

#### Anthropic models (external)

Currently there are two Anthropic models which are currently under Preview, they are accessible in early release environments.

- **Claude Sonnet 4.5** is Anthropic's newest, coding and agent-focused model.
- **Claude Opus 4.1** is a reasoning-focused model.

OpenAI remains as the default model for new agents in Copilot Studio and you have the flexibility in selecting either of these models.

Both are available in Microsoft Copilot Studio as opt-in preview (Frontier Program) models rather than General Availability (GA), meaning they‚Äôre for early experimental use only. The table below compares their status, strengths, and ideal use cases in the Copilot Studio context:

| Model Version | Status | Key Strengths | Ideal Use Cases |
|-------|----------|-------------|-----------|
| **Claude Sonnet 4.5** | External Preview | - Enterprise-ready safety: Improved alignment, reduced prompt injection risk, and strong error correction. - Advanced reasoning & math: Significant gains in multi-step reasoning and computational accuracy. | - Building autonomous coding agents and developer copilots. - Complex, multi-step workflows - Enterprise AI agents requiring long context and sustained reasoning. |
| **Claude Opus 4.1** | External Preview | - Deep reasoning and complex problem-solving - Creative and multilingual so suitable for content generation, translation and narrative writing | - High stakes reasoning: legal, financial or scientific analysis - Enterprise research agents: synthesizing insights from large datasets -Advanced coding projects: multi-file refactoring, debugging, and architectural design - Creative generation: marketing copy, long-form content, multilingual support. |

!!! warning

    - It's important to note that these are external models. Anthropic models are hosted outside Microsoft and are subject to Anthropic terms and data handling, which need to be reviewed and accepted before makers can use them. These models are available before an official release so that you can get early access and‚ÄØ[provide feedback](https://community.powerplatform.com/forums/thread/?groupid=db8f53c2-767d-47d6-a1ae-fe4c828a6553). Therefore is not recommended to use these models for Production purposes.

    - Please note that you could also experience slowdowns or timeouts due to limited capacity and availability, and these models might not be supported in the future. Admins can control access to this feature (more of this soon as you progress from here!).

#### üî¢ Context length and data training

All the above models are capable with large context windows. For instance, GPT-4.1 supports up to 128K tokens of context. They are all trained on data up to mid-2024 (GPT-5 on slightly later data). This means they _know_ information up to those cut-off dates, which is useful for understanding their knowledge limitations when they generate answers.

### üîß Changing and updating the model of your agent

By default, a new Copilot agent starts on the GPT-4o model, which is optimized as a balanced choice for most scenarios.

You can switch the agent‚Äôs primary model anytime via the agent‚Äôs **Settings** page ‚û°Ô∏è **Model** section in the **Generative AI** tab, using a simple dropdown to pick from available models.

![Agent models available](./assets/5.0_01_AgentModels.png)

This flexibility allows you to experiment with different models even after your agent is built. For example, switching to an experimental model to evaluate if it improves answer quality for your use case.

## üì∂ Model updates and retired models

Microsoft periodically upgrades the available models to newer versions. Notably, in July 2025, several models were automatically upgraded:

- GPT-4.1 **replaced** the older GPT-4o Mini as the Basic tier model (same cost).
- GPT-4.1 (full) **replaced** the GPT-4o model as the Standard tier, now generally available.
- The o3 model (GA) **replaced** the previous o1 model for Premium tier reasoning tasks.

!!! note ""

    Refer to [Model updates](https://learn.microsoft.com/en-us/ai-builder/prompt-modelsettings#model-updates) periodically to understand model updates made by Microsoft.

If your agent was using GPT-4o or o1, it would have been transparently moved to the new equivalent model with no change in billing rates. Additionally, in August 2025, the GPT-5 Chat and Reasoning models were added as previews.

### üß∂ Why might you continue using a "Retired" model?

With AI model upgrades happening automatically, Copilot Studio provides a safety valve for continuity. You may have cases where you need to stick with the previous model for a short time, even after an upgrade.

For example, to maintain compatibility, to meet compliance requirements, or simply because your solution‚Äôs behavior with the new model needs evaluation before fully switching over. Microsoft recognizes this and allows makers to continue using a retired model for up to **30 days** after an automatic upgrade.

- **Compatibility**: Perhaps the new model‚Äôs outputs differ in format or content. If your downstream systems or prompts expect the old model‚Äôs style, you might need time to adjust your logic. The grace period lets you run on the known model while you update and test your agent with the new model in a controlled way. You can make adjustments without disrupting users.

- **Compliance & Data Policies**: Some organizations have strict vetting for AI models. An experimental new model might not yet be approved for use, or it might handle data in a different way (for example, the new model might use data centres in different regions). If that‚Äôs a concern, an admin might decide to delay the switch until compliance checks are done.

- **Specific Business Needs**: You might have a mission-critical event (product launch, demo) where stability is more important than getting new features quickly. Sticking with the older model ensures no surprises during that period.

### üå≥ How to use a retired model

On your agent‚Äôs **Settings** page, in the **Model** section in the **Generative AI** tab, there is a toggle option labeled **"Continue using retired models"**. This becomes available when a model update is rolled out.

![Setting for Continue using retired models](./assets/5.0_02_ContinueUsingRetiredModels.png)

If you switch this on, your agent will remain on the previous model version for that 30-day window. During that window, you can toggle between the old and new model to compare responses and gradually roll over. After 30 days, the old model is fully removed from service, so you should plan to move to the new model by then. In practice, this feature offers a buffer to support a smooth transition.

#### Example

Suppose your agent was using GPT-4o and it got upgraded to GPT-4.1. If you notice the AI‚Äôs tone changed or it uses slightly different phrasing that doesn‚Äôt align with your established conversational style, you could toggle on ‚Äúuse retired model‚Äù to temporarily revert to GPT-4o.

You then have a few weeks to update your prompts/instructions to suit GPT-4.1‚Äôs style (maybe adding an instruction like ‚Äúkeep responses brief‚Äù) and test thoroughly. Test your agent on GPT-4.1 in a safe environment, and then disable the retired model toggle once confident. This way, your end users have a consistent experience during the transition.

## üîê Admin controls for AI model selection

It‚Äôs worth noting that not every copilot environment allows all model choices by default. There are organization-level settings that tenant administrators control. This is especially relevant for experimental models. Organizations may want to restrict who can use preview AI models (since they might process data in non-standard ways or outside certain regions).

Here are the key admin controls affecting which models a maker/developer can select for an agent:

- **Enable Anthropic models to be used within your organization**: An admin with the **Global administrator** role needs to enable (allow) anthropic models in the Microsoft 365 Admin Center. If this setting is disabled, only OpenAI models will be available to select.

![Allow Anthropic provider setting in Microsoft 365 admin center](./assets/5.0_05_AllowAnthropicProvider.png)

- **Allow Preview (Experimental) models to be used in Copilot Studio environments**: An admin can toggle whether preview and experimental AI models are available in a given environment. If this is turned **off**, makers/developers will only see generally-available models (like GPT-4o) in the dropdown.

    To use GPT-5 or any future preview, the admin must turn this setting **on** for that specific environment.

![Enable external model setting](./assets/5.0_03_EnableExternalModelsSetting.png)

- **Move data across regions**: Because experimental models may not run in the same regional data centres as standard models, enabling them often requires allowing cross-region data movement. In the Power Platform admin centre (environment settings), there is a setting called **Move data across regions**. This must be turned on by the admin if you want to permit experimental model usage. It acknowledges that data processed by these models may leave your organization's geographic boundaries.

    For example, if your environment is in _Europe_ and an experimental model is only hosted in _US_ datacenters, this setting needs to be enabled to let that data flow happen. If it‚Äôs disabled, Copilot won‚Äôt use those models.

![Move data across regions settings](./assets/5.0_04_MoveDataAcrossRegions.png)

These admin settings ensure that **organizations stay in control** of sensitive aspects like data residency and feature stability. As a developer building an agent, if you find that the option for GPT-5 preview models are missing or you see a warning about generative AI not being available, it could be that your admin has disabled experimental models or hasn‚Äôt enabled cross-region data movement. In such cases, you‚Äôd need to contact your tenant admin to adjust the environment settings if experimental features are desired.

For a quick reference, here‚Äôs a summary of the admin controls related to model selection:

| Admin Setting | Effect on Model selection | Setting location |
|----------|------------|------------|
| **Allow Anthropic models** | When **Allowed**, users can connect to the Anthropic external models for agents built in Copilot Studio. When **disabled**, only OpenAI models are available. | Microsoft 365 Admin Center |
| **Allow Preview & Experimental Models** | When **ON**, makers can choose preview/experimental AI models (for example GPT-5 Chat) for their agents. When **OFF**, only production-ready models are available. | Power Platform admin center |
| **Move Data Across Regions** | Required to be **ON** if experimental models are enabled. It permits data from the agent to be processed and stored outside the home region. If this is OFF, any model that would require cross-region data flow will be blocked, leading to the agent's generative AI features being unavailable. Managed in the Power Platform admin centre by a tenant administrator. | Power Platform admin center |

!!! tip
    - If you‚Äôre an **admin** concerned about data compliance, disable the use of Anthropic models + keep the preview models off and cross-region data moving off.
    - If you‚Äôre a **developer** in a highly regulated industry environment, you may need to stick to General Availability (GA) models unless you get clearance to use preview models (OpenAI) or external preview models (Anthropic).

## üî† Response Formatting

Once you‚Äôve sorted out _what_ your agent will say by picking the right model and providing good instructions, the next focus is _how_ the answer should look when delivered to the user.

**Response Formatting** in Copilot Studio refers to defining the style and structure of the AI‚Äôs replies - such as whether text should be bold or italic, if links can be included, or if any dynamic content/expressions should be inserted.

### üñºÔ∏è Why Response Formatting matters

It‚Äôs all about readability and user experience. Even the most correct answer can confuse or frustrate a user if it‚Äôs a blob of unstructured text. By applying consistent formatting, you ensure key information stands out and the answer is easy to scan.

For example,

- **bold** text can highlight an important number or term
- **lists** can break complex instructions into steps
- **hyperlinks** can point the user to additional resources without overcrowding the answer

Additionally, your brand‚Äôs style or tone should be reflected in formatting choices. For instance, a formal agent might avoid emojis and use bold text for emphasis, while a playful one might use italics to highlight lighthearted or humorous comments.

In Copilot Studio‚Äôs generative answer node, you can allow or disallow certain formatting in the responses. Let‚Äôs go through what options exist and how to use them effectively.

## üñåÔ∏è Available formatting options

Copilot Studio generative answers support a subset of Markdown for rich text. Here are the main formatting elements you can leverage in the AI‚Äôs responses, and what they do:

| Formatting Option | Purpose and Effect  | Example Usage |
|----------|------------|---------|
| **Bold** | Makes important words or phrases stand out. Use bold to highlight key | **"Your account balance is $1,250."** - The amount is bold so it‚Äôs immediately noticeable.  |
| _Italics_ | Adds subtle emphasis or denotes special terms. Commonly used for document titles, or to highlight a _phrase_ in a softer way than bold. | _"Please provide additional details for verification."_ - The words ‚Äúadditional details‚Äù are italicized to indicate a prompt or placeholder. |
| Hyperlinks | Inserts clickable links in the response text. Useful for directing users to external articles, internal knowledge base, or any detailed reference. | "Refer to our [Microsoft Surface Warranty and Protection Plans](https://www.microsoft.com/surface/business/warranty-protection-plans-and-support) for more details." - The text "Microsoft Surface Warranty and Protection Plans" is a hyperlink to the web page. |
| Power Fx expressions | Embeds dynamic content or logic-driven text in the response. Power Fx can pull in variables, do calculations, or enforce formatting (even with regex for validation). This allows parts of the answer to be determined by real-time data or conditions. | "Today is `${Text(Now(), "dddd, mmmm d, yyyy")}`." - This uses a Power Fx formula to insert the current date in a long format, `Friday, October 3, 2025`. You could also use expressions to format numbers, or ensure an output meets a pattern (using regex). |

!!! tip
    Always test your response formatting using the testing pane in Copilot Studio. Try out sample user questions. See if the agent‚Äôs answer is coming through with the formatting you expect. If something is not right, such as the response shows markdown syntax in text instead of formatting it, you may need to adjust the instructions. Sometimes the model might not be sure it‚Äôs allowed to use formatting and will ‚Äúplay safe‚Äù by showing the markdown syntax such as raw asterisks. Clarify in the formatting instructions and repeat testing till you're satisfied.

## ‚≠ê Best practices for formatting responses

Now that we know what we _can_ do, let‚Äôs talk about what we _should_ do to make the AI‚Äôs answers clear and effective. Here are some best practices, aimed at developers crafting the agent‚Äôs behavior:

- **Be consistent with style**: Establish a consistent format for similar types of responses.

    For example, you might provide the following instructions: `Term in bold, followed by a colon, then the definition in regular text.`

    Do that every time for a definition.

    Or if the agent is listing multiple options, always use a bulleted list rather than sometimes bullets, sometimes a paragraph.

    Consistency helps users quickly understand the structure of the answer. You can enforce this by specifying it in instructions: `"Always answer with bullet points when listing options."`

- **Use emphasis sparingly but meaningfully**: Apply **bold** to the most crucial information only - typically one or two words or a short phrase that the user should not miss. Avoid bolding entire paragraphs or large chunks, as that defeats the purpose.

    Use _italics_ for secondary emphasis or to denote something like an example input or a note. For instance, italicizing error messages or user-provided text can differentiate it from the rest of the agent‚Äôs output.

- **Leverage lists for structure**: When an answer contains multiple pieces of information or a step-by-step process, don‚Äôt bury it in a sentence. If it‚Äôs naturally a sequence, use a numbered list (1, 2, 3, ‚Ä¶). If it‚Äôs an unordered collection, like features of a product, use bullet points.

- **Mind the tone along with format**: The formatting should complement the agent‚Äôs tone. If your agent‚Äôs persona is very formal, you might avoid using exclamation marks or casual emphasis. If it‚Äôs friendly, maybe an occasional bold ‚ÄúGreat choice!‚Äù is fine. The tone is primarily set by language, but formatting can amplify it. A friendly chatty agent might even use emoticons or emojis (if appropriate) - though use those sparingly and only if they fit the use case.

- **Check hyperlink texts**: When including hyperlinks in answers, make sure the link text is descriptive of what it leads to. This not only looks more professional but also aids accessibility.

    For example, `"download the report here"` is not as good as `"download the Quarterly Report"` where _"Quarterly Report"_ is the hyperlink. Ensure the URLs are correct and the user has permission to access them if they are internal sites.

- **Utilize Power Fx for dynamic formatting**: A powerful aspect for developers is that you can combine the generative answer with Power Fx expressions to refine the output.

    For instance, suppose the initial response is `"Your order total is 1250 usd.‚Äù` You could use a Power Fx formula to format that number as US currency and replace `"usd"` with the dollar symbol, resulting in `"$1,250.00"`.

    You might do this with a formula like: `"$" & Text(ThisItem.OrderTotal, "[$-en-US]#,##0.00")`

    This formula ensures the number is formatted with commas and two decimal places, following US conventions.

    Similarly, if generative AI provides a date in an undesirable format, a Power Fx expression could re-format it. Essentially, you can post-process the AI‚Äôs text to enforce any strict patterns.

- **Validate and extract text using regex**: TBC

- **Aim for readability**: After applying all the above, always put yourself in the user‚Äôs perspective and read the output. Is it easy to find the main point? Is the response unnecessarily long? Often, less is more. If the AI tends to be very verbose, consider instructing it to be concise or limiting the scope of answers.

    On the other hand, if the answer is too short or lacks detail, you might want to add instructions asking for more explanation or examples.

    The format can only do so much - the content quality must be there. A good balance is a short answer that addresses the query, followed by a hyperlink or an option to get more info. For instance, `"Your password was reset successfully. You will receive a confirmation email shortly. If you did not request this, please head to [https://support.example.com](https://support.microsoft.com)."` - This is clear, and the additional info (contact support) is given via a hyperlink rather than a big paragraph about what to do.

In summary, use formatting to enhance clarity, not distract. The user should be able to glance at the agent‚Äôs answer and grasp the needed information quickly. As a developer, utilize the **Response Formatting** in the **Generative AI** tab under the **Settings** of your agent to ensure the output is polished. Always test a variety of questions to see how the formatting holds up, and adjust your instructions as needed.

## Lab

- Navigate to agent settings and put in a prompt to customize the tone, outputs and personality of the agent

[Multi-agent orchestration and more: Copilot Studio announcements](https://www.microsoft.com/microsoft-copilot/blog/copilot-studio/multi-agent-orchestration-maker-controls-and-more-microsoft-copilot-studio-announcements-at-microsoft-build-2025/#copilot-studio-enhancements)
(Scroll down a bit to the response section of the blog)
